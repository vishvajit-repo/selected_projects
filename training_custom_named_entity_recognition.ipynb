{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815f1840",
      "metadata": {
        "tags": [],
        "id": "815f1840",
        "outputId": "17cd588a-2f3b-4453-916a-526a4d5c7eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting protobuf==3.20.*\n",
            "  Using cached protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.4\n",
            "    Uninstalling protobuf-3.19.4:\n",
            "      Successfully uninstalled protobuf-3.19.4\n",
            "Successfully installed protobuf-3.20.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.20.*\n",
        "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8dc042f",
      "metadata": {
        "id": "c8dc042f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0a9542",
      "metadata": {
        "tags": [],
        "id": "9f0a9542"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import IPython\n",
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install ipywidgets\n",
        "IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810dd679",
      "metadata": {
        "id": "810dd679"
      },
      "source": [
        "### Installing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670570fb",
      "metadata": {
        "tags": [],
        "id": "670570fb",
        "outputId": "dac163dd-fccc-4f85-911d-7ca37d9ff58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.32.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.1.1)\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2022.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting seqeval\n",
            "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.8/site-packages (from seqeval) (1.22.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.8/site-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.0)\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.13.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (60.9.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.22.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.10.2+cu113)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.1.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval\n",
        "!pip install tensorflow\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49c8fa1c",
      "metadata": {
        "id": "49c8fa1c"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc375309",
      "metadata": {
        "tags": [],
        "id": "dc375309"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942f4633",
      "metadata": {
        "tags": [],
        "id": "942f4633"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import tensorflow\n",
        "torch.cuda.is_available()\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig,BertForTokenClassification, AdamW,get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow. keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from seqeval.metrics import accuracy_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941359f6",
      "metadata": {
        "tags": [],
        "id": "941359f6",
        "outputId": "8412ade8-284b-4c53-8199-4c05ee827ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CUDA available? True\n",
            "CUDA device:  0\n",
            "CUDA device name:  Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print('\\nCUDA available?', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA device: ', torch.cuda.current_device())\n",
        "    print('CUDA device name: ', torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "128007bb-56e8-4de4-89cf-e581f37675ef",
      "metadata": {
        "tags": [],
        "id": "128007bb-56e8-4de4-89cf-e581f37675ef"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, AutoModelForTokenClassification\n",
        "tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f94bb4f",
      "metadata": {
        "id": "2f94bb4f"
      },
      "source": [
        "### Formatting the data for Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04fa8443",
      "metadata": {
        "tags": [],
        "id": "04fa8443"
      },
      "outputs": [],
      "source": [
        "import os,ast\n",
        "lst=os.listdir('/root/bio_tagged')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd98633c",
      "metadata": {
        "tags": [],
        "id": "cd98633c"
      },
      "outputs": [],
      "source": [
        "lst=['NERIOBdataV1.jsonl', 'ner_labels_100.csv', 'ner_labels_500.csv', 'ner_new_labels_2286.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f41f5c6",
      "metadata": {
        "tags": [],
        "id": "3f41f5c6",
        "outputId": "4507b0ff-39f9-44da-bf11-e5c4c8b8cf68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-232874a3e0d4>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data=data.append(df)\n",
            "<ipython-input-8-232874a3e0d4>:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data= data.append(df)\n",
            "<ipython-input-8-232874a3e0d4>:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data= data.append(df)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1584, 2)\n",
            "(1685, 2)\n",
            "(2186, 2)\n",
            "(4471, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-232874a3e0d4>:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data= data.append(df)\n"
          ]
        }
      ],
      "source": [
        "data=pd.DataFrame()\n",
        "for i in lst:\n",
        "    if i.endswith('jsonl') or i.endswith('manifest'):\n",
        "        df=pd.read_json('/root/bio_tagged/'+i,lines=True)\n",
        "        df=df[['tokens', 'tags']]\n",
        "        data=data.append(df)\n",
        "        print(data.shape)\n",
        "    else:\n",
        "        df=pd.read_csv('/root/bio_tagged/'+i)\n",
        "        df['tokens']=df['tokens'].apply(lambda x:ast.literal_eval(x))\n",
        "        df['tags']=df['tags'].apply(lambda x:ast.literal_eval(x))\n",
        "        df=df[['tokens', 'tags']]\n",
        "        data= data.append(df)\n",
        "        print(data.shape)\n",
        "data=data[['tokens','tags']]\n",
        "#data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71114e7b",
      "metadata": {
        "tags": [],
        "id": "71114e7b"
      },
      "outputs": [],
      "source": [
        "##labels list\n",
        "labels_lst=data['tags'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37eaf9c7",
      "metadata": {
        "id": "37eaf9c7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646bfa32",
      "metadata": {
        "tags": [],
        "id": "646bfa32"
      },
      "outputs": [],
      "source": [
        "##Keeping unique labels for each entity\n",
        "final_labels=[]\n",
        "#lab_lst=[i.lower() for i in lab_lst]\n",
        "for i in labels_lst:\n",
        "  x=[]\n",
        "  for j in i:\n",
        "    if j!='O':\n",
        "      p=j[:2]+j[2:].lower()\n",
        "      p=p.replace('/','_')\n",
        "      x.append(p)\n",
        "    else:\n",
        "      x.append('O')\n",
        "  final_labels.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25ea67a-c70c-45f6-9dd5-4f1a5402282c",
      "metadata": {
        "tags": [],
        "id": "d25ea67a-c70c-45f6-9dd5-4f1a5402282c"
      },
      "outputs": [],
      "source": [
        "##Labels to be trained\n",
        "lab_lst=['issue_problem','feature', 'benefit', 'routine']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81036590-eaa1-45d2-bb27-4eb41a4535dc",
      "metadata": {
        "tags": [],
        "id": "81036590-eaa1-45d2-bb27-4eb41a4535dc"
      },
      "outputs": [],
      "source": [
        "# lab_lst=['brand','product_type','condition','ingredient','time','body_part']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5147da",
      "metadata": {
        "tags": [],
        "id": "ac5147da"
      },
      "outputs": [],
      "source": [
        "##Removing minority class labels\n",
        "final_labels_1=[]\n",
        "#lab_lst=[i.lower() for i in lab_lst]\n",
        "for i in final_labels:\n",
        "  x=[]\n",
        "  for j in i:\n",
        "    if j!='O' and j[2:].lower() in lab_lst:\n",
        "      p=j[:2]+j[2:].lower()\n",
        "      p=p.replace('/','_')\n",
        "      x.append(p)\n",
        "    else:\n",
        "      x.append('O')\n",
        "  final_labels_1.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95251318",
      "metadata": {
        "tags": [],
        "id": "95251318"
      },
      "outputs": [],
      "source": [
        "data['tags']=final_labels_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a24853",
      "metadata": {
        "tags": [],
        "id": "91a24853",
        "outputId": "37cf4987-99c5-4e77-f299-63d568eca383"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4471, 2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7caee0cb",
      "metadata": {
        "tags": [],
        "id": "7caee0cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "data = shuffle(data,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c9492c",
      "metadata": {
        "tags": [],
        "id": "18c9492c"
      },
      "outputs": [],
      "source": [
        "## Filtering samples without any required entity\n",
        "data['tags_length']=data['tags'].apply(lambda x: len([i for i in x if i=='O']))\n",
        "data['token_length']=data['tokens'].apply(lambda x: len(x))\n",
        "data['flag']=data['tags_length']==data['token_length']\n",
        "data=data[data['flag']==False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd77782",
      "metadata": {
        "tags": [],
        "id": "fbd77782",
        "outputId": "8a2f5e8d-9786-499d-c790-b2fac5fd59f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1634, 5)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3ecd2e",
      "metadata": {
        "tags": [],
        "id": "ef3ecd2e"
      },
      "outputs": [],
      "source": [
        "# tokens level data after Exploding\n",
        "data['id']=[i for i in range(data.shape[0])]\n",
        "data=data.explode(['tokens','tags'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45497580",
      "metadata": {
        "tags": [],
        "id": "45497580",
        "outputId": "6269e548-c561-47c0-b74f-f231f0a3a202"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "O                  87882\n",
              "I-benefit           2131\n",
              "I-feature           1733\n",
              "B-benefit           1625\n",
              "I-issue_problem     1598\n",
              "B-feature           1063\n",
              "I-routine            886\n",
              "B-routine            529\n",
              "B-issue_problem      412\n",
              "Name: tags, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['tags'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127f75fe",
      "metadata": {
        "tags": [],
        "id": "127f75fe"
      },
      "outputs": [],
      "source": [
        "## Transforming original tokens to BERT tokenized form\n",
        "class GetSentence(object):\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "        self.n_sentences = 1\n",
        "        self.empty = False\n",
        "        agg_function = lambda s: [(w,t) for w,t in zip(s[\"tokens\"].values.tolist(),\n",
        "                                                        s[\"tags\"].values.tolist())]\n",
        "        self.group = self.data.groupby('id').apply(agg_function)\n",
        "        self.sentence = [s for s in self.group]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0a6c7c",
      "metadata": {
        "tags": [],
        "id": "3c0a6c7c"
      },
      "outputs": [],
      "source": [
        "getter = GetSentence(data)\n",
        "sentence = [[word[0] for word in sentence] for sentence in getter.sentence]\n",
        "labels = [[lab[1] for lab in sentence] for sentence in getter.sentence]\n",
        "tag_values = list(dict.fromkeys(data[\"tags\"].values))\n",
        "tag_values.append('PAD')\n",
        "tag_idx = {'O': 0, 'B-issue_problem': 1, 'I-issue_problem': 2, 'B-feature': 3, 'I-feature': 4, 'B-benefit': 5, 'I-benefit': 6, 'B-routine': 7, 'I-routine': 8, 'PAD': 9}\n",
        "# tag_idx={'O': 0, 'B-condition': 1, 'B-time': 2, 'I-time': 3, 'B-product_type': 4, 'I-product_type': 5, 'B-brand': 6, 'B-body_part': 7, 'I-brand': 8, 'I-condition': 9, 'B-ingredient': 10, 'I-body_part': 11, 'I-ingredient': 12, 'PAD': 13}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ee7607",
      "metadata": {
        "tags": [],
        "id": "14ee7607"
      },
      "outputs": [],
      "source": [
        "id2label= {t: i for i, t in tag_idx.items()}\n",
        "label2id = {i: t for i, t in tag_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad12e0d9",
      "metadata": {
        "tags": [],
        "id": "ad12e0d9",
        "outputId": "4cf0fdd9-4c45-4b0b-9a6d-ac64c8aa1d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'O': 0, 'B-issue_problem': 1, 'I-issue_problem': 2, 'B-feature': 3, 'I-feature': 4, 'B-benefit': 5, 'I-benefit': 6, 'B-routine': 7, 'I-routine': 8, 'PAD': 9}\n"
          ]
        }
      ],
      "source": [
        "print(label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13259ff8",
      "metadata": {
        "tags": [],
        "id": "13259ff8"
      },
      "source": [
        "###### Encoding the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b092dae2",
      "metadata": {
        "tags": [],
        "id": "b092dae2"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747f46bb",
      "metadata": {
        "tags": [],
        "id": "747f46bb"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dda3944",
      "metadata": {
        "tags": [],
        "id": "8dda3944"
      },
      "outputs": [],
      "source": [
        "## Returns tokenized sentence with labels\n",
        "def tokenize_preserve(sentences,text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentences,text_labels):\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "        labels.extend([label]*n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4b42bf",
      "metadata": {
        "tags": [],
        "id": "cd4b42bf"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_and_labels = [\n",
        "  tokenize_preserve(sent,labs)\n",
        "  for sent,labs in zip(sentence,labels)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8098bdc8",
      "metadata": {
        "tags": [],
        "id": "8098bdc8"
      },
      "outputs": [],
      "source": [
        "##Creating new rows of data for samples with token >512\n",
        "tokenized_texts_and_labels_1=[]\n",
        "x=0\n",
        "for i in tokenized_texts_and_labels:\n",
        "  tokens=i[0]\n",
        "  labels=i[1]\n",
        "  if len(tokens)<512:\n",
        "    tokenized_texts_and_labels_1.append((tokens,labels))\n",
        "  else:\n",
        "    cnt=len(tokens)//512+1\n",
        "    for j in range(0,cnt):\n",
        "      ind=512*j\n",
        "      x+=1\n",
        "      tokenized_texts_and_labels_1.append((tokens[ind:ind+512],labels[ind:ind+512]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4fb4f7",
      "metadata": {
        "tags": [],
        "id": "fc4fb4f7"
      },
      "outputs": [],
      "source": [
        "tokenized_text = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_1]\n",
        "labels = [token_label_pair[1]for token_label_pair in tokenized_texts_and_labels_1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530ece30",
      "metadata": {
        "tags": [],
        "id": "530ece30"
      },
      "outputs": [],
      "source": [
        "## Generating Input_ids, tags and masks vectors\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_text],\n",
        "                         maxlen=MAX_LEN, dtype='long',value=0.0,\n",
        "                         truncating='post',padding='post')\n",
        "tags = pad_sequences([[tag_idx.get(l)for l in lab]for lab in labels],\n",
        "                    maxlen=MAX_LEN, dtype='long', value=tag_idx['PAD'],\n",
        "                    truncating='post',padding='post')\n",
        "attention_masks = [[float(i !=0.0)for i in ii]for ii in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7996bff4",
      "metadata": {
        "tags": [],
        "id": "7996bff4"
      },
      "outputs": [],
      "source": [
        "## Splitting data into train, text and validation\n",
        "tr_input, test_input,tr_tag, test_tag,tr_masks,test_masks = train_test_split(input_ids,tags,attention_masks,random_state=45,test_size=.2)\n",
        "tr_input, val_input,tr_tag, val_tag,tr_masks,val_masks = train_test_split(tr_input,tr_tag,tr_masks,random_state=45,test_size=.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9ffefb",
      "metadata": {
        "tags": [],
        "id": "3c9ffefb",
        "outputId": "ea5263d5-0bbf-42da-c5b8-cc1851e6a379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1056, 512), (264, 512), (1056, 512), (331, 512))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_input.shape,val_input.shape,tr_tag.shape,test_input.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf237d2",
      "metadata": {
        "id": "9cf237d2"
      },
      "source": [
        "### Adding the data to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd6fdb2",
      "metadata": {
        "tags": [],
        "id": "5dd6fdb2"
      },
      "outputs": [],
      "source": [
        "tr_input = torch.tensor(tr_input)\n",
        "val_input = torch.tensor(val_input)\n",
        "tr_tag = torch.tensor(tr_tag)\n",
        "val_tag = torch.tensor(val_tag)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "\n",
        "test_input = torch.tensor(test_input)\n",
        "test_tag = torch.tensor(test_tag)\n",
        "test_masks = torch.tensor(test_masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c25d18b9",
      "metadata": {
        "tags": [],
        "id": "c25d18b9"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(tr_input, tr_masks, tr_tag)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_data = TensorDataset(val_input, val_masks,val_tag)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d87c616b-3f5b-4804-b631-fb9ab414f5f7",
      "metadata": {
        "tags": [],
        "id": "d87c616b-3f5b-4804-b631-fb9ab414f5f7"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_data = TensorDataset(test_input, test_masks,test_tag)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299462f3",
      "metadata": {
        "id": "299462f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a6144670",
      "metadata": {
        "id": "a6144670"
      },
      "source": [
        "## Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cadc05",
      "metadata": {
        "tags": [],
        "id": "d9cadc05",
        "outputId": "8905718b-ae89-44c1-bc13-8ef050d18821"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel, AutoTokenizer, AdamW, get_cosine_schedule_with_warmup\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\",num_labels=len(label2id),ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa8b065d-7fd6-44ab-b3a1-22ea194dc574",
      "metadata": {
        "tags": [],
        "id": "fa8b065d-7fd6-44ab-b3a1-22ea194dc574"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adamax,AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4a430c-05ba-414a-b254-5581b09cb087",
      "metadata": {
        "tags": [],
        "id": "ed4a430c-05ba-414a-b254-5581b09cb087"
      },
      "outputs": [],
      "source": [
        "###### Defining the training arguments\n",
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=4e-5,\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "\n",
        "epochs = 40\n",
        "max_grad_norm = 1\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5639f0",
      "metadata": {
        "tags": [],
        "id": "0d5639f0",
        "outputId": "3da21bb0-db08-4ac6-baa0-3804c90e114f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForTokenClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e407f43-e070-45f8-862c-5de854174357",
      "metadata": {
        "tags": [],
        "id": "3e407f43-e070-45f8-862c-5de854174357"
      },
      "outputs": [],
      "source": [
        "## Training of NER\n",
        "from time import time\n",
        "start = time()\n",
        "loss_values, validation_loss_values = [], []\n",
        "cnt=0\n",
        "epch=0\n",
        "\n",
        "for _ in trange(epochs, desc= \"Epoch\"):\n",
        "    if cnt==0:\n",
        "    #/|\\==>TRAINLOOP(ONEPASS)<==\\|/\n",
        "        model.train()\n",
        "        total_loss=0 #so it resets each epoch\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch #also the order in train_data/val_data\n",
        "\n",
        "            model.zero_grad() #clearing previous gradients for each epoch\n",
        "\n",
        "            outputs = model(b_input_ids,\n",
        "                           attention_mask=b_input_mask, labels=b_labels)#forward pass\n",
        "\n",
        "            loss = outputs[0]\n",
        "            loss.backward() #getting the loss and performing backward pass\n",
        "\n",
        "            total_loss += loss.item() #tracking loss\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "            #^^^ preventing exploding grads\n",
        "\n",
        "            optimizer.step() #updates parameters\n",
        "\n",
        "            scheduler.step() #update learning_rate\n",
        "\n",
        "        avg_train_loss = total_loss/len(train_dataloader)\n",
        "        print('Average train loss : {}'.format(avg_train_loss))\n",
        "\n",
        "        loss_values.append(avg_train_loss) #storing loss values if you choose to plot learning curve\n",
        "\n",
        "        #/|\\==>VALIDATION(ONEPASS)<==\\|/\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        predictions, true_labels = [], []\n",
        "\n",
        "        for batch in valid_dataloader:\n",
        "            batch = tuple(t.to(device)for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids,\n",
        "                               attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "            logits = outputs[1].detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            eval_loss += outputs[0].mean().item()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.extend(label_ids)\n",
        "        eval_loss = eval_loss / len(valid_dataloader)\n",
        "        validation_loss_values.append(eval_loss)\n",
        "        print('Validation loss: {}'.format(eval_loss))\n",
        "\n",
        "        pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                    for p_i, l_i, in zip(p,l)if tag_values[l_i] !='PAD']\n",
        "\n",
        "        valid_tags = [tag_values[l_i]for l in true_labels\n",
        "                     for l_i in l if tag_values[l_i] !='PAD']\n",
        "\n",
        "        print('Validation Accuracy: {}'.format(accuracy_score(pred_tags,valid_tags)))\n",
        "\n",
        "        print('Validation F-1 Score:{}'.format(f1_score([pred_tags], [valid_tags])))\n",
        "\n",
        "        model.save_pretrained('/root/bio_tagged/models/epoch_'+str(epch))\n",
        "\n",
        "\n",
        "\n",
        "print(f'Time taken to run: {time() - start} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a1a7c4-5bd7-4b1f-9f8e-6b5e02d0a47d",
      "metadata": {
        "id": "86a1a7c4-5bd7-4b1f-9f8e-6b5e02d0a47d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9ef31f-bcb1-47fb-8fd7-5aab02643a44",
      "metadata": {
        "tags": [],
        "id": "6e9ef31f-bcb1-47fb-8fd7-5aab02643a44"
      },
      "outputs": [],
      "source": [
        "## Loading trained model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"/root/bio_tagged/models/epoch_20\",num_labels=len(label2id),ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626420a0-e157-4a7e-abc5-107d326ecbef",
      "metadata": {
        "tags": [],
        "id": "626420a0-e157-4a7e-abc5-107d326ecbef",
        "outputId": "5a55320d-c778-42b4-cdb1-dd1a4efbd412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForTokenClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84805254-d2e8-4106-9d1d-f6da374bbf2b",
      "metadata": {
        "tags": [],
        "id": "84805254-d2e8-4106-9d1d-f6da374bbf2b",
        "outputId": "63b1499d-c61a-4289-c25d-396b96e73119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "      benefit       0.93      0.90      0.92       288\n",
            "      feature       0.96      0.93      0.94       115\n",
            "issue_problem       0.93      0.97      0.95       601\n",
            "      routine       0.96      0.95      0.95       560\n",
            "\n",
            "    micro avg       0.94      0.95      0.94      1564\n",
            "    macro avg       0.94      0.94      0.94      1564\n",
            " weighted avg       0.94      0.95      0.94      1564\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##Validation Data\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device)for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                       attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "            for p_i, l_i, in zip(p,l)if tag_values[l_i] !='PAD']\n",
        "\n",
        "valid_tags = [tag_values[l_i]for l in true_labels\n",
        "             for l_i in l if tag_values[l_i] !='PAD']\n",
        "\n",
        "display(print(classification_report([pred_tags], [valid_tags])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109fa6bd-cc9b-45f2-b0b8-56d41f028ae9",
      "metadata": {
        "tags": [],
        "id": "109fa6bd-cc9b-45f2-b0b8-56d41f028ae9",
        "outputId": "2840f18c-305e-45dc-8d1a-df4f637a5530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "      benefit       0.91      0.87      0.89       436\n",
            "      feature       0.81      0.89      0.85        97\n",
            "issue_problem       0.87      0.94      0.91       658\n",
            "      routine       0.95      0.85      0.89       753\n",
            "\n",
            "    micro avg       0.90      0.89      0.89      1944\n",
            "    macro avg       0.88      0.89      0.88      1944\n",
            " weighted avg       0.91      0.89      0.89      1944\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##Test data\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = tuple(t.to(device)for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                       attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "            for p_i, l_i, in zip(p,l)if tag_values[l_i] !='PAD']\n",
        "\n",
        "test_tags = [tag_values[l_i]for l in true_labels\n",
        "             for l_i in l if tag_values[l_i] !='PAD']\n",
        "\n",
        "display(print(classification_report([pred_tags], [test_tags])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1790df-53eb-426a-94d9-aed8c97c2315",
      "metadata": {
        "id": "ab1790df-53eb-426a-94d9-aed8c97c2315"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b89870a-17db-4675-a467-7c53ef217822",
      "metadata": {
        "id": "5b89870a-17db-4675-a467-7c53ef217822"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a36f313-671a-4e36-9cad-8c5cf27c1ac6",
      "metadata": {
        "id": "2a36f313-671a-4e36-9cad-8c5cf27c1ac6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7dd55a-a5b5-4970-949e-303b0ed51d7f",
      "metadata": {
        "id": "2a7dd55a-a5b5-4970-949e-303b0ed51d7f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab0703a-bdd6-44c8-807a-7356b879c010",
      "metadata": {
        "id": "5ab0703a-bdd6-44c8-807a-7356b879c010"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bcc596-4242-4475-955d-41b442079081",
      "metadata": {
        "id": "05bcc596-4242-4475-955d-41b442079081"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3a74dc-cac4-4885-ae57-795095e144e7",
      "metadata": {
        "id": "0f3a74dc-cac4-4885-ae57-795095e144e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc4084c-e802-428d-ab3e-8ae2e1323eba",
      "metadata": {
        "id": "6fc4084c-e802-428d-ab3e-8ae2e1323eba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da6ad92-81e8-49fe-8fb9-6e64085803db",
      "metadata": {
        "id": "4da6ad92-81e8-49fe-8fb9-6e64085803db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3ef14a-2b1f-439a-af81-6f9c7c6af65c",
      "metadata": {
        "id": "ec3ef14a-2b1f-439a-af81-6f9c7c6af65c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "instance_type": "ml.g4dn.xlarge",
    "kernelspec": {
      "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}